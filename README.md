Customer Support Chatbot
This repository contains a Streamlit application for a customer support chatbot powered by an LSTM-based natural language processing (NLP) model. The chatbot predicts user intents based on input queries and provides appropriate responses using a dataset from Kaggle. The application allows users to interact with the chatbot through a web interface and includes functionality to handle customer support queries related to orders, payments, refunds, and more.
Features

Interactive Chat Interface: Users can input queries via a chat interface, and the chatbot responds based on predicted intents.
Intent Prediction: Uses a trained LSTM model to classify user queries into intents (e.g., order status, refund request).
Dynamic Responses: Responses are selected from a predefined set based on the predicted intent, with a confidence threshold to handle unclear inputs.
Pre-trained Model: Includes a pre-trained LSTM model and tokenizer for intent classification.
Streamlit Web App: Built with Streamlit for an easy-to-use, web-based interface.

Dataset
The application uses the Bitext Gen AI Chatbot Customer Support Dataset from Kaggle, available here. The dataset (Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv) must be placed in the same directory as the application code.
Prerequisites

Python 3.7 or higher
Required Python libraries:
streamlit
tensorflow
pandas
numpy
joblib


(Optional) pyngrok for exposing the app to a public URL
An ngrok authtoken (if using pyngrok for public access)

Installation

Clone the Repository:
git clone https://github.com/<your-username>/<your-repo-name>.git
cd <your-repo-name>


Install Dependencies:Install the required Python libraries using pip:
pip install -r requirements.txt

If you don't have a requirements.txt file, you can install the libraries directly:
pip install streamlit tensorflow pandas numpy joblib

For public access via ngrok:
pip install pyngrok


Download the Dataset:

Download the Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv file from the Kaggle dataset.
Place the CSV file in the root directory of the project.


Download Pre-trained Model and Data:

Ensure the model.h5, tokenizer.pkl, and dialogflow_data.pkl files are available in the project directory. These files are generated by the training script and are required for the Streamlit app to function.
If you need to train the model yourself, run the training script (customer_support_chatbott.py) in a Jupyter notebook or Colab environment to generate these files.



Usage

Run the Application Locally:In the project directory, run the following command:
streamlit run app.py

This will start the Streamlit server, and a URL (typically http://localhost:8501) will be displayed in the terminal.

Run with Public Access (Optional):To expose the app to a public URL using ngrok:

Set up your ngrok authtoken (sign up at ngrok.com to get one):ngrok authtoken <your-ngrok-authtoken>


Start the Streamlit app and ngrok:streamlit run app.py &> /dev/null &
ngrok http 8501


Copy the public URL provided by ngrok (e.g., https://<random-id>.ngrok.io) and open it in a web browser.


Interact with the Chatbot:

Open the provided URL in a web browser.
Type a query in the chat input field (e.g., "Where is my order?" or "I need a refund").
The chatbot will predict the intent and respond with an appropriate message from the dataset.
If the confidence score is below 0.5, the chatbot will ask for clarification.



File Structure

app.py: The main Streamlit application script.
customer_support_chatbott.py: The training script for preprocessing data, training the LSTM model, and saving the model and data files.
Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv: The dataset file (must be downloaded from Kaggle).
model.h5: The pre-trained LSTM model.
tokenizer.pkl: The tokenizer used for text preprocessing.
dialogflow_data.pkl: The processed intent and response data.
README.md: This file, containing project documentation.
(Optional) requirements.txt: Lists the required Python libraries.

Training the Model
To retrain the model or generate the required files (model.h5, tokenizer.pkl, dialogflow_data.pkl):

Run the customer_support_chatbott.py script in a Jupyter notebook or Google Colab environment.
Ensure the dataset (Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv) is available.
The script will preprocess the data, train the LSTM model, and save the necessary files.

Notes

Dataset: Ensure the Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv file is in the project directory, or update the file path in app.py if it's located elsewhere.
Model Files: The model.h5, tokenizer.pkl, and dialogflow_data.pkl files must be present for the app to work. If they are missing, run the training script to generate them.
Ngrok: Using ngrok is optional and requires an authtoken. Without it, the app can still run locally on http://localhost:8501.
Dialogflow Integration: The original script includes notes on integrating with Dialogflow via webhooks or APIs. This functionality is not implemented in the Streamlit app but can be extended by setting up a webhook server.
Performance: The pre-trained model achieves high accuracy (as reported in the training script). If performance issues arise, consider adjusting the model architecture or hyperparameters as noted in the script.

Example
After running the app, you can:

Type queries like "Track my order" or "How do I cancel my subscription?" in the chat input.
The chatbot will classify the intent and respond with a relevant message, such as "Please provide your order number to track your order."
If the query is unclear (confidence < 0.5), the chatbot will respond with "I'm sorry, I didn't understand that. Can you please rephrase?"

License
This project is licensed under the MIT License. See the LICENSE file for details.
Acknowledgments

The dataset is sourced from Kaggle.
Built with Streamlit and TensorFlow.
Uses ngrok for optional public access.
